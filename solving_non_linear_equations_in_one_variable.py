# -*- coding: utf-8 -*-
"""Solving Non-Linear Equations in One Variable.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1su13U5uDPWUVgxAi1zkXqnE9e5-mwgpI

We are interested in solving the equation $f(x)=0$ where $f$ is a real-valued function and satisfy a variety of conditions depending upon the method that we employ to approximate the solutions. For now, assume $f:\mathbb{R}\to\mathbb{R}$ is defined as
$$f(x):=2x^3-\frac{5}{2}x-5$$
Note that
$$f'(x)=6x^2-\frac{5}{2}$$
However, using symbolic differentiation would be kind of cheating at this point. So, we use the following definition of derivatives
$$f'(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$
and approximate the derivative using a very small value of $h$ (say $10^{-10}$). Therefore,
$$f'(x)\approx \frac{f(x+10^{-10})-f(x)}{10^{-10}}$$
"""

import numpy as np

#Defining the function
def f(x):
  return 2*x**3-2.5*x-5


# The derivative of f is now computed.
def der_f(x):
  return (f(x+10**(-10))-f(x))/(10**(-10))

"""Now we plot the graph of $f$ to get a better idea of how this function behaves."""

# Let's have a look at the graph of f.

import matplotlib.pyplot as plt

x = np.linspace(-1.5,2,1000)
y = f(x)

plt.plot(x,y)
plt.grid('True')
plt.xlabel('$x$')
plt.ylabel('$f(x)$')
plt.title('Graph of $f(x)$')
plt.show()

"""For all the methods we are discussing here, only the Newton-Raphson method needs ONE guess value $(x_0)$ is needed. For the remaining, we need two guess values ($a$ and $b$) with special consideration that the root $x^*\in[a,b]$ for the bisection, regula-falsi and improved regula-falsi methods. Here, we initialise $a=1,b=2$ and the tolearance value $\mathrm{tol}=10^{-5}$%."""

a=1.0
b=2.0
tol=0.00001

"""We create a table to store and display our obtained results."""

# Creating the dataframe for displaying results

import pandas as pd

cols_bm={'Iteration':[],'a':[],'b':[],'c':[],'f(c)':[],'Relative Absolute Error':[]}
cols_rf={'Iteration':[],'a':[],'b':[],'c':[],'f(c)':[],'Relative Absolute Error':[]}
cols_mrf={'Iteration':[],'a':[],'b':[],'c':[],'f(c)':[],'Relative Absolute Error':[]}
cols_sm={'Iteration':[],'a':[],'b':[],'c':[],'f(c)':[],'Relative Absolute Error':[]}
cols_nrm={'Iteration':[],'a':[],'f(a)':[],'Relative Absolute Error':[]}

"""Here we present the bisection method algorithm."""

# Bisection Method

c=(a+b)/2 # mid-point

cols_bm['Iteration'].append(0)
cols_bm['a'].append(a)
cols_bm['b'].append(b)
cols_bm['c'].append(c)
cols_bm['f(c)'].append(f(c))
cols_bm['Relative Absolute Error'].append('NaN')

if f(a)*f(b)>=0: print("These guess values won't work!") # Are the guess values alright?

elif f(a)*f(b)<0:
   for i in range(1,1000):
     c_old = c # storing the previous value of c
     if f(a)*f(c)<0: # root lies between a and c
       b=c
       c=(a+b)/2
     elif f(c)*f(b)<0: # root lies between c and b
       a=c
       c=(a+b)/2
     elif f(c)==0: break # c is a root
     err = (abs(c_old-c)/abs(c))*100 # calculation of relative absolute error
     cols_bm['Iteration'].append(i)
     cols_bm['a'].append(a)
     cols_bm['b'].append(b)
     cols_bm['c'].append(c)
     cols_bm['f(c)'].append(f(c))
     cols_bm['Relative Absolute Error'].append(err)
     if err<tol: break # breaking condition



# Displaying the results
df_bm = pd.DataFrame(cols_bm)
df_bm

"""According to the bisection method, the required root is $1.660100$.

The values of $a$ and $b$ have been update. So, we reinitialise them.
"""

# Reinitialisation

a = 1.0
b = 2.0

"""Here we present the regula falsi algorithm."""

# Regula Falsi Method

c=(a*abs(f(b))+b*abs(f(a)))/(abs(f(a))+abs(f(b))) # possible root?

cols_rf['Iteration'].append(0)
cols_rf['a'].append(a)
cols_rf['b'].append(b)
cols_rf['c'].append(c)
cols_rf['f(c)'].append(f(c))
cols_rf['Relative Absolute Error'].append('NaN')

if f(a)*f(b)>=0: print("These guess values won't work!") # Are the guess values alright?

elif f(a)*f(b)<0:
   for i in range(1,1000):
     c_old = c # storing the previous value of c
     if f(a)*f(c)<0: # root lies between a and c
       b=c
       c=(a*abs(f(b))+b*abs(f(a)))/(abs(f(a))+abs(f(b)))
     elif f(c)*f(b)<0: # root lies between c and b
       a=c
       c=(a*abs(f(b))+b*abs(f(a)))/(abs(f(a))+abs(f(b)))
     elif f(c)==0: break # c is a root
     err = (abs(c_old-c)/abs(c))*100 # calculation of relative absolute error
     cols_rf['Iteration'].append(i)
     cols_rf['a'].append(a)
     cols_rf['b'].append(b)
     cols_rf['c'].append(c)
     cols_rf['f(c)'].append(f(c))
     cols_rf['Relative Absolute Error'].append(err)
     if err<tol: break # breaking condition


# Displying the obtained results
df_rf = pd.DataFrame(cols_rf)
df_rf

"""Again, the regula falsi method also tells us that the required root is $1.660100$.

Here we present the modified/improved regula falsi method.
"""

# Reinitialising the values of a and b
a = 1.0
b = 2.0

# Modified Regula Falsi Method

c=(a*abs(f(b))+b*abs(f(a)))/(abs(f(a))+abs(f(b))) # possible root?

cols_mrf['Iteration'].append(0)
cols_mrf['a'].append(a)
cols_mrf['b'].append(b)
cols_mrf['c'].append(c)
cols_mrf['f(c)'].append(f(c))
cols_mrf['Relative Absolute Error'].append('NaN')

if f(a)*f(b)>=0: print("These guess values won't work!") # Are the guess values alright?

elif f(a)*f(b)<0:
  for i in range(1,1000):
    c_old = c # storing the previous value of c
    if f(a)*f(c)<0: # root lies between a and c
      b=c
      c=(a*abs(f(b))+b*abs(f(a)/2))/(abs(f(a)/2)+abs(f(b)))
    elif f(c)*f(b)<0: # root lies between c and b
      a=c
      c=(a*abs(f(b)/2)+b*abs(f(a)))/(abs(f(a))+abs(f(b)/2))
    elif f(c)==0: break # c is a root
    err = (abs(c_old-c)/abs(c))*100 # calculation of relative absolute error
    cols_mrf['Iteration'].append(i)
    cols_mrf['a'].append(a)
    cols_mrf['b'].append(b)
    cols_mrf['c'].append(c)
    cols_mrf['f(c)'].append(f(c))
    cols_mrf['Relative Absolute Error'].append(err)
    if err<tol: break # breaking condition


# Displaying the results
df_mrf = pd.DataFrame(cols_mrf)
df_mrf

"""Again, the root is $1.660100$.

Hwe we present the algorithm for the secant method.
"""

# Secant Method

#Reinitialising a and b
a = 1.0
b = 2.0

cols_sm['Iteration'].append(0)
cols_sm['a'].append(a)
cols_sm['b'].append(b)
cols_sm['c'].append(b-((f(b))/(((f(b)-f(a)))/(b-a))))
cols_sm['f(c)'].append(f(b-((f(b))/(((f(b)-f(a)))/(b-a)))))
cols_sm['Relative Absolute Error'].append('NaN')

for i in range(1,1000):
   c_old=b
   c=b-((f(b))/(((f(b)-f(a)))/(b-a)))
   a=b
   b=c
   err = (abs(c_old-c)/abs(c))*100 # calculation of relative absolute error
   cols_sm['Iteration'].append(i)
   cols_sm['a'].append(a)
   cols_sm['b'].append(b)
   cols_sm['c'].append(c)
   cols_sm['f(c)'].append(f(c))
   cols_sm['Relative Absolute Error'].append(err)
   if err<tol: break # breaking condition


#Displaying the results
df_sm = pd.DataFrame(cols_sm)
df_sm

"""Again, the required root (using the secant method) is $1.660100$.

Now, we present the Newton-Raphson method. The initial guess value $a$ is initialised to $1$.
"""

# Newton-Raphson Method

a = 1.0

cols_nrm['Iteration'].append(0)
cols_nrm['a'].append(a)
cols_nrm['f(a)'].append(f(a))
cols_nrm['Relative Absolute Error'].append('NaN')

for i in range(0,1000):
   a_old=a
   a=a-((f(a))/(der_f(a)))
   err = (abs(a_old-a)/abs(a))*100 # calculation of relative absolute error
   cols_nrm['Iteration'].append(i+1)
   cols_nrm['a'].append(a)
   cols_nrm['f(a)'].append(f(a))
   cols_nrm['Relative Absolute Error'].append(err)
   if err<tol: break # breaking condition


# Displaying the results
df_nrm = pd.DataFrame(cols_nrm)
df_nrm

"""This time too the root is $1.660100$."""